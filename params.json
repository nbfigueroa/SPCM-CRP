{
  "name": "Spectral Polytope Covariance Matrix - Chinese Restaurant Process (SPCM-CRP)",
  "tagline": "Non-parametric clustering of transformed Covariance matrices.",
  "body": "# SPCM-CRP\r\n\r\nSPCM-CRP : Transform Invariant Chinese Restaurant Process for Covariance Matrices  \r\nWebsite: http://nbfigueroa.github.io/SPCM-CRP/  \r\nAuthor: Nadia Figueroa (nadia.figueroafernandez AT epfl.ch)\r\n\r\nThis repo provides code for running the Non-parametric Spectral Clustering algorithm on Covariance Matrix Datasets (SPCM-CRP) introduced in [1]. In a nutshell, **SPCM-CRP** is a similarity-dependent Chinese Restaurant process. Where the similarity matrix comes from the Spectral Polytope Covariance Matrix Similarity function and the non-parametric clustering is applied on the spectral manifold of the similarity function.\r\n\r\n### Illustrative Example\r\nTo highlight the power of the proposed method, we consider a dataset of 5 Covariance Matrices of 3-dimensions, which can be illustrated as ellipsoids in 3D space:\r\n<p align=\"center\">\r\n<img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/3d-ellipsoids.png\" width=\"700\">\r\n</p>\r\nThe dataset is generated by **two distinct Covariance matrices** which are randomly transformed (rotation, scale, noise). The similar matrices are depicted by the colors of their ellipsoids.\r\n\r\n**Our goal** is to cluster this dataset with a transform-invariant metric that will give us the two expected clusters.\r\n\r\n### Spectral Polytope Covariance Matrix (SPCM) Similarity Function\r\nSeldom Covariance Matrix similarity functions explictly have the property of transform-invariance. In this work, I propose such a similarity function which uses the idea of a **Spectral Polytope** together with the concept of **homothety**.\r\n<p align=\"center\">\r\n<img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/sigmas_mod.png\" width=\"700\">\r\n</p>\r\n\r\nThe **Spectral Polytope (SP)** is the Convex envelope of the projection of the Eigenvectors scaled by their Eigenvalues (X). The idea is, if the SPs of two covariance matrices have the same shape but are scaled by some homothetic factor, then they are similar (Refer to [1] for the math). By implementing this simple, yet elegant idea, we get robust transform-invariant similarity values (second plot is the B-SPCM - a bounded version of SPCM):\r\n\r\n<p align=\"center\">\r\n<img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/SPCM.png\" width=\"300\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/BSPCM.png\" width=\"300\">\r\n</p>\r\n\r\nwhich are not well recovered by other metrics (RIEM, LERM, KLDM, JBLD):\r\n\r\n<p align=\"center\">\r\n<img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/RIEM.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/LERM.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/KLDM.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/JBLD.png\" width=\"200\">\r\n</p>\r\n\r\n- RIEM: Affine Invariant Riemannian Metric\r\n- LERM: Log-Euclidean Riemannian Metric\r\n- KLDM: Kullback-Liebler Divergence Metric\r\n- JBLD: Jensen-Bregman LogDet Divergence\r\n\r\n### Similarity-based Non-parametric clustering (sd - Chinese Restaurant Process)\r\nNow that we have a good similarity function for our task, we want to derive a clustering mechanism that is free of model selection and robust to intializations. Thus, we choose a variant of the Chinese Resturant Process, namely the **sd-CRP** [2] whose priors for cluster assigment are driven by the similarity values and the data is clustered on the Spectral Manifold of the Similarity matrix of the Dataset.\r\n\r\n#### sd-CRP steps\r\n- Initially, we apply an **augmented Spectral Dimenensionality** [1] reduction algorithm, which automatically selects the dimensionality of the Spectral Manifold by applying a SoftMax on the Eigenvalues of the Laplacian of the Similarity matrix:\r\n\r\n  <p align=\"center\">\r\n  <img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/auto-spectral-manifold.png\" width=\"500\">\r\n  </p>\r\n\r\n- Once we have the points on the Spectral Manifold corresponding to each Covariance Matrix, we apply the **sd-CRP**. Which follows the analogy for seating customers in a Chinese Restaurant with infinite number of tables wrt. a similarity between the customers\r\n  <p align=\"center\">\r\n  <img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/ddcrp.png\" width=\"500\">\r\n  </p>\r\n  Each customer chooses to sit with another customer or alone according to a prior dependent on the **SPCM similarity function**. Table assignments z(c), then emerge from linked customers or cycles, regardless of sequence or ordering.\r\n\r\nTo run the full SPCM-CRP pipeline, follow the scipt ```demo_sdCRP.m```, for the 3D dataset you should get the following output on your MATLAB terminal:\r\n\r\n```\r\nClustering via sd-CRP...\r\n*** Initialized with 5 clusters out of 5 observations ***\r\nIteration 1: Started with 5 clusters --> moved to 3 clusters with logprob = -23.35\r\nIteration 2: Started with 3 clusters --> moved to 2 clusters with logprob = -22.03\r\nIteration 3: Started with 2 clusters --> moved to 2 clusters with logprob = -22.03\r\nIteration 4: Started with 2 clusters --> moved to 2 clusters with logprob = -22.57\r\nIteration 5: Started with 2 clusters --> moved to 3 clusters with logprob = -23.91\r\nIteration 6: Started with 3 clusters --> moved to 2 clusters with logprob = -22.22\r\nIteration 7: Started with 2 clusters --> moved to 2 clusters with logprob = -22.57\r\nIteration 8: Started with 2 clusters --> moved to 2 clusters with logprob = -21.68\r\nIteration 9: Started with 2 clusters --> moved to 3 clusters with logprob = -23.89\r\nIteration 10: Started with 3 clusters --> moved to 2 clusters with logprob = -21.68\r\nIteration 11: Started with 2 clusters --> moved to 2 clusters with logprob = -22.25\r\nIteration 12: Started with 2 clusters --> moved to 3 clusters with logprob = -23.04\r\nIteration 13: Started with 3 clusters --> moved to 2 clusters with logprob = -22.22\r\nIteration 14: Started with 2 clusters --> moved to 2 clusters with logprob = -22.59\r\nIteration 15: Started with 2 clusters --> moved to 2 clusters with logprob = -22.59\r\nIteration 16: Started with 2 clusters --> moved to 2 clusters with logprob = -22.25\r\nIteration 17: Started with 2 clusters --> moved to 2 clusters with logprob = -22.03\r\nIteration 18: Started with 2 clusters --> moved to 3 clusters with logprob = -23.61\r\nIteration 19: Started with 3 clusters --> moved to 2 clusters with logprob = -22.25\r\nIteration 20: Started with 2 clusters --> moved to 2 clusters with logprob = -21.68\r\nElapsed time is 0.179722 seconds.\r\nMAP Cluster estimate recovered at iter 8: 2\r\nsd-CRP LP: -2.168154e+01 and Purity: 1.00, NMI Score: 1.00, F measure: 1.00 \r\n*************************************************************\r\n```\r\n\r\nThe result is:\r\n\r\n  <p align=\"center\">\r\n  <img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/sdCRP_results.png\" width=\"500\">\r\n  </p>\r\n\r\n**without** selecting or optimizing for **ANY** hyper-parameters.\r\n\r\n### Comparisons\r\n\r\n- In ```demo_comparisons.m`` I provide extensive comparisons between the SPCM similarity function and the 4 other standard Covariance Matrix Similarity functions used in literature for datasets of increasing dimensionality and samples [1], for example a 6D Covariance matrix dataset with 30 samples are well discriminated with SPCM and B-SPCM:\r\n \r\n  <p align=\"center\">\r\n  <img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/SPCM_30.png\" width=\"300\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/BSPCM_30.png\" width=\"300\">\r\n  </p>\r\n  \r\n  while the othe functions (RIEM, LERM, KLDM, JBLD) do not show apparent partitions to the naked eye:\r\n  \r\n  <p align=\"center\">\r\n  <img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/RIEM_30.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/LERM_30.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/KLDM_30.png\" width=\"200\"><img src=\"https://github.com/nbfigueroa/SPCM-CRP/blob/master/img/JBLD_30.png\" width=\"200\">\r\n  </p>\r\n\r\n\r\n- Also, you can compare the SPCM-CRP to standard Similarity-based clustering algorithms like Affinity Propapgation and Spectral Clustering with k-means [1].\r\n\r\n#### Dependencies\r\nTo run the **comparisons** demo, download the following toolbox and make sure to have it in your MATLAB path:\r\n- [ML_toolbox](https://github.com/epfl-lasa/ML_toolbox): Machine learning toolbox containing a plethora of dimensionality reduction, clustering, classification and regression algorithms accompanying the [Advanced Machine Learning](http://lasa.epfl.ch/teaching/lectures/ML_MSc_Advanced/index.php) course imparted at EPFL by Prof. Aude Billard.\r\n\r\nIf you're not interested in running comparisons, this step is not needed.\r\n\r\n### Publication\r\n[1] Nadia Figueroa and Aude Billard, \"Transform Invariant Discovery of Dynamical Primitives: Leveraging Spectral and Bayesian Non-parametric Methods.\" *In preparation*.  \r\n[2] Richard Socher, Andrew Maas and Christopher D. Manning. \"Spectral Chinese Restaurant Processes: Nonparametric Clustering\r\nBased on Similarities\" In proceedings of th 14th International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}